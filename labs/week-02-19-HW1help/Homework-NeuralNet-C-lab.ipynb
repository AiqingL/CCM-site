{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Neural networks - Part C (20 points)\n",
    "# === CCM LAB EDITION ===\n",
    "## A neural network model of semantic cognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"semcog_net.jpeg\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid, relu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load in the names of all the items, attributes, and relations into Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/sem_items.txt','r') as fid:\n",
    "    names_items = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_relations.txt','r') as fid:\n",
    "    names_relations = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_attributes.txt','r') as fid:\n",
    "    names_attributes = np.array([l.strip() for l in fid.readlines()])\n",
    "        \n",
    "# number of objects / relations / attributes\n",
    "nobj = len(names_items)\n",
    "nrel = len(names_relations)\n",
    "nattributes = len(names_attributes)\n",
    "\n",
    "print('List of items:')\n",
    "print(names_items)\n",
    "print(nobj)\n",
    "\n",
    "print(\"List of relations:\")\n",
    "print(names_relations)\n",
    "print(nrel)\n",
    "\n",
    "print(\"List of attributes:\")\n",
    "print(names_attributes)\n",
    "print(nattributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load in the data matrix from a text file too. The matrix `D` has a row for each training pattern. It is split into a matrix of input patterns `input_pats` (item and relation) and their corresponding output patterns `output_pats` (attributes). The are `N` patterns total in the set.\n",
    "\n",
    "For each input pattern, the first 8 elements indicate which item is being presented, and the next 4 indicate which relation is being queried. Each element of the output pattern corresponds to a different attribute. All patterns use 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next, let's load in the data matrix from a text file too.\n",
    "D = np.loadtxt('data/sem_data.txt')\n",
    "# The matrix D has a row for each training pattern.\n",
    "\n",
    "# It is split into a matrix of input patterns input_pats (item and relation) \n",
    "input_pats = D[:,:nobj+nrel]\n",
    "input_pats = torch.tensor(input_pats,dtype=torch.float)\n",
    "\n",
    "# and their corresponding output patterns output_pats (attributes).\n",
    "output_pats = D[:,nobj+nrel:]\n",
    "output_pats = torch.tensor(output_pats,dtype=torch.float)\n",
    "\n",
    "# The are N patterns total in the set.\n",
    "N = input_pats.shape[0] # number of training patterns\n",
    "\n",
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "output_v = output_pats[0,:].numpy().astype('bool')\n",
    "\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "\n",
    "print('Example output pattern:')\n",
    "print(output_v.astype('int'))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Which encodes...\")\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:8]])\n",
    "\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[8:]])\n",
    "\n",
    "print('Attributes ',end='')\n",
    "print(names_attributes[output_v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= CCM LAB EDITION ============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"ugly.jpg\" style=\"width: 350px;\"/>\n",
    "\"Auto-encoder\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.i2h = nn.Linear(8+4,15)\n",
    "        self.h2o = nn.Linear(15,8+4)\n",
    "        # add code\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,nobj+nrel) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        hidden = self.i2h(x)\n",
    "        hidden = relu(hidden)\n",
    "        output = self.h2o(hidden)\n",
    "        output = sigmoid(output)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a completed function `train` for stochastic gradient descent. The network makes online (rather than batch) updates, adjusting its weights after the presentation of each input pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden = mynet(input_pats[p,:]) # forward pass\n",
    "            target = input_pats[p,:] \n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:8]])\n",
    "\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[8:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output, hidden = mynet(input_pats[0,:]) # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if time, talk about concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated = torch.cat((layer1,layer2),1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
