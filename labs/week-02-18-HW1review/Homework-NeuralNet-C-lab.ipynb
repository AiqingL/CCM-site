{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 Review - Neural networks\n",
    "# === CCM LAB EDITION ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"semcog_net.jpeg\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this lab, we'll go over a simple variant of the network in Part C of the homework\n",
    "* We'll start by loading in the data just like we would in the homework\n",
    "* Then build a network for a **different** model architecture (see below)\n",
    "* And demonstrate how you would train that model using the PyTorch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid, relu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load in the names of all the items, attributes, and relations into Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of items:\n",
      "['Pine' 'Oak' 'Rose' 'Daisy' 'Robin' 'Canary' 'Sunfish' 'Salmon']\n",
      "8\n",
      "List of relations:\n",
      "['ISA' 'Is' 'Can' 'Has']\n",
      "4\n",
      "List of attributes:\n",
      "['Living thing' 'Plant' 'Animal' 'Tree' 'Flower' 'Bird' 'Fish' 'Pine'\n",
      " 'Oak' 'Rose' 'Daisy' 'Robin' 'Canary' 'Sunfish' 'Salmon' 'Pretty' 'Big'\n",
      " 'Living' 'Green' 'Red' 'Yellow' 'Grow' 'Move' 'Swim' 'Fly' 'Sing' 'Skin'\n",
      " 'Roots' 'Leaves' 'Bark' 'Branch' 'Petals' 'Wings' 'Feathers' 'Gills'\n",
      " 'Scales']\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "with open('data/sem_items.txt','r') as fid:\n",
    "    names_items = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_relations.txt','r') as fid:\n",
    "    names_relations = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_attributes.txt','r') as fid:\n",
    "    names_attributes = np.array([l.strip() for l in fid.readlines()])\n",
    "        \n",
    "# number of objects / relations / attributes\n",
    "nobj = len(names_items)\n",
    "nrel = len(names_relations)\n",
    "nattributes = len(names_attributes)\n",
    "\n",
    "print('List of items:')\n",
    "print(names_items)\n",
    "print(nobj)\n",
    "\n",
    "print(\"List of relations:\")\n",
    "print(names_relations)\n",
    "print(nrel)\n",
    "\n",
    "print(\"List of attributes:\")\n",
    "print(names_attributes)\n",
    "print(nattributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load in the data matrix from a text file too. The matrix `D` has a row for each training pattern. It is split into a matrix of input patterns `input_pats` (item and relation) and their corresponding output patterns `output_pats` (attributes). There are `N` patterns total in the set.\n",
    "\n",
    "For each input pattern, the first 8 elements indicate which item is being presented, and the next 4 indicate which relation is being queried. Each element of the output pattern corresponds to a different attribute. All patterns use 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input pattern:\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Example output pattern:\n",
      "[1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Which encodes...\n",
      "Item ['Pine']\n",
      "Relation ['ISA']\n",
      "Attributes ['Living thing' 'Plant' 'Tree' 'Pine']\n"
     ]
    }
   ],
   "source": [
    "# Next, let's load in the data matrix from a text file too.\n",
    "D = np.loadtxt('data/sem_data.txt')\n",
    "# The matrix D has a row for each training pattern.\n",
    "\n",
    "# It is split into a matrix of input patterns input_pats (item and relation) \n",
    "input_pats = D[:,:nobj+nrel]\n",
    "input_pats = torch.tensor(input_pats,dtype=torch.float)\n",
    "\n",
    "# and their corresponding output patterns output_pats (attributes).\n",
    "output_pats = D[:,nobj+nrel:]\n",
    "output_pats = torch.tensor(output_pats,dtype=torch.float)\n",
    "\n",
    "# The are N patterns total in the set.\n",
    "N = input_pats.shape[0] # number of training patterns\n",
    "\n",
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "output_v = output_pats[0,:].numpy().astype('bool')\n",
    "\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "\n",
    "print('Example output pattern:')\n",
    "print(output_v.astype('int'))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Which encodes...\")\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:8]])\n",
    "\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[8:]])\n",
    "\n",
    "print('Attributes ',end='')\n",
    "print(names_attributes[output_v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= CCM LAB EDITION ============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"ugly.jpg\" style=\"width: 350px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here, we will build an \"ugly\" version of the full model\n",
    "* Each feature and relation is connected to a 15 node hidden layer and this layer is also connected to a 15 unit output layer.\n",
    "* We will implement a relu function in the hidden layer and a sigmoid function in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.i2h = nn.Linear(8+4,15)\n",
    "        self.h2o = nn.Linear(15,8+4)\n",
    "        # add code\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,nobj+nrel) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        hidden = self.i2h(x)\n",
    "        hidden = relu(hidden)\n",
    "        output = self.h2o(hidden)\n",
    "        output = sigmoid(output)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a completed function `train` for stochastic gradient descent. The network makes online (rather than batch) updates, adjusting its weights after the presentation of each input pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden = mynet(input_pats[p,:]) # forward pass\n",
    "            target = input_pats[p,:] \n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.25\n",
      "epoch 50 loss 0.11\n",
      "epoch 100 loss 0.074\n",
      "epoch 150 loss 0.056\n",
      "epoch 200 loss 0.037\n",
      "epoch 250 loss 0.018\n",
      "epoch 300 loss 0.009\n",
      "epoch 350 loss 0.005\n",
      "epoch 400 loss 0.003\n",
      "epoch 450 loss 0.002\n",
      "epoch 500 loss 0.002\n",
      "epoch 550 loss 0.001\n",
      "epoch 600 loss 0.001\n",
      "epoch 650 loss 0.001\n",
      "epoch 700 loss 0.001\n",
      "epoch 750 loss 0.001\n",
      "epoch 800 loss 0.001\n",
      "epoch 850 loss 0.001\n",
      "epoch 900 loss 0.001\n",
      "epoch 950 loss 0.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input pattern:\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Item ['Pine']\n",
      "Relation ['ISA']\n"
     ]
    }
   ],
   "source": [
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:8]])\n",
    "\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[8:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "output, hidden = mynet(input_pats[0,:]) # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9607, 0.0010, 0.0155, 0.0242, 0.0108, 0.0072, 0.0050, 0.0239, 0.9855,\n",
       "         0.0108, 0.0140, 0.0028]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
       "       grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If time:\n",
    "* Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9075, 0.5936]])\n",
      "tensor([[0.1407, 0.3876]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 2)\n",
    "print(x)\n",
    "y = torch.rand(1,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9075, 0.5936, 0.1407, 0.3876]])\n"
     ]
    }
   ],
   "source": [
    "concatenated = torch.cat((x,y),1)\n",
    "print(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
